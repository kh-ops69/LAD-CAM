# Query2CAD

## Abstract
Computer Aided Design (CAD) engineers typically do not achieve their best prototypes in a single attempt. Instead, they iterate and refine their designs to achieve an optimal solution through multiple revisions. This traditional approach, though effective, is time-consuming and relies heavily on the expertise of skilled engineers. To address these challenges, we introduce Query2CAD, a novel framework to generate CAD designs. The framework uses a large language model to generate executable CAD macros. Additionally, Query2CAD refines the generation of the CAD model with the help of its self-refinement loops. Query2CAD operates without supervised data or additional training, using the LLM as both a generator and a refiner. The refiner leverages feedback generated by the BLIP2 model, and to address false negatives, we have incorporated human-in-the-loop feedback into our system. Additionally, we have developed a dataset that encompasses most operations used in CAD model designing and have evaluated our framework using this dataset. Our findings reveal that when we used GPT-4 Turbo as our language model, the architecture achieved a success rate of 53.6% on the first attempt. With subsequent refinements, the success rate increased by 23.1%. In particular, the most significant improvement in the success rate was observed with the first iteration of the refinement. With subsequent refinements, the accuracy of the correct designs did not improve significantly.

## How to run the system
1. Download and setup the [FreeCAD](https://github.com/FreeCAD/FreeCAD) software. The system has been tested on Windows and Linux OS with a screen size of 1920x1080.
2. Clone the repository.
```
git clone https://github.com/akshay140601/Query2CAD.git
```

3. Set up Together AI API to use Llama models or get the API key of OpenAI to use GPT models. Take a look at args in src/run.py for arguments that you can specify. Assuming the keys are already set, run the below command to run the system.
```
python src/run.py --code_gen_model codellama/chatgpt/llama3/gpt4-turbo --reasoning_model codellama/chatgpt/llama3/gpt4-turbo --human_feedback True
```

4. The results will be stored in the results/ folder and new queries can be added in data/queries.txt
